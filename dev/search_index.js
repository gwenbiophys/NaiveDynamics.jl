var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order   = [:module, :type, :constant, :function, :macro]","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [NaiveDynamics]\nOrder   = [:module, :type, :constant, :function, :macro]","category":"page"},{"location":"api/#NaiveDynamics.GenericRandomCollector","page":"API","title":"NaiveDynamics.GenericRandomCollector","text":"Collector\n\nCollector super-type for simulation initialization.\n\n\n\n\n\n","category":"type"},{"location":"api/#NaiveDynamics.unique_pairlist-Tuple{AbstractArray}","page":"API","title":"NaiveDynamics.unique_pairlist","text":"unique_pairlist(a::AbstractArray)\n\nReturn a vector of static vectors, wherein each static vector is a unique pair of objects from the array of a. In the case of position, the return pair list is a vector of static vectors of 2 mutable vectors of 3 floats each.\n\nThis is the most Naive pairlist writer.\n\n\n\n\n\n","category":"method"},{"location":"helpGwen/#Gwen's-Handy-Helpers","page":"Gwen's Handy Helpers","title":"Gwen's Handy Helpers","text":"","category":"section"},{"location":"helpGwen/#A-dirty-list-of-instructions-and-links-and-references","page":"Gwen's Handy Helpers","title":"A dirty list of instructions and links and references","text":"","category":"section"},{"location":"helpGwen/#add-a-new-package-to-a-dev-package's-source","page":"Gwen's Handy Helpers","title":"add a new package to a dev package's source","text":"","category":"section"},{"location":"helpGwen/","page":"Gwen's Handy Helpers","title":"Gwen's Handy Helpers","text":"pgk() activate NaiveDynamics.jl\n    add NewPackages\n","category":"page"},{"location":"helpGwen/#getting-a-new-REPL-started-after-changing-a-type","page":"Gwen's Handy Helpers","title":"getting a new REPL started after changing a type","text":"","category":"section"},{"location":"helpGwen/","page":"Gwen's Handy Helpers","title":"Gwen's Handy Helpers","text":"I do believe using Revise is unnecessary, as VSCode supposedly already runs it. I havent noticed any issues, but I havent tested specifically if it works. Also, until I change the directory name, I must put NaiveDynamics.jl, not NaiveDynamics. That will mess life up!","category":"page"},{"location":"helpGwen/","page":"Gwen's Handy Helpers","title":"Gwen's Handy Helpers","text":"pgk() dev ./NaiveDynamics.jl\nusing Revise\nusing NaiveDynamics","category":"page"},{"location":"devdiary/#Developer-Diary","page":"Developer Diary","title":"Developer Diary","text":"","category":"section"},{"location":"devdiary/#1.-Let's-document-27-April","page":"Developer Diary","title":"1. Let's document - 27 April","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Today has been an interesting day. I have been working on my baseline code but really hardening my documentation so that I have a well collected space to start hucking my thoughts. ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"For instance, I added CSV and NamedArrays .jl to prepare for testing on whether the ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"mutable struct GenericObjectCollection <: ObjectCollection \n    name::AbstractArray{String, 1}\n\n    position::AbstractArray{AbstractFloat, 3}\n    velocity::AbstractArray{AbstractFloat, 3}\n\n    uniqueID::AbstractArray{UUID,1}\n\nend","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"makes any sense, or if I should place all this information into a single array. And then I could test how this version of GenericObjectCollection scales, comparing it against a NamedArray convention. The primary point is to minimize processing time on putting these arrays together, while keeping my function accesses to data meaningful. I do not want the following:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Collection = [AbstractArray{String, 1}, AbstractArray{AbstractFloat, 3}, AbstractArray{AbstractFloat, 3}]\nfunction do_something(Collection)\n    return Collection[1] - Collection[2]\nend","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"in which function writing depends on making sure I have the right index of my Collection, so I don't do something stupid, like add a force term to a velocity term. I admit, something like position = Collection[3] is reallly easy, but we are here for overengineered solutions. ;)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"But then my julia package would not precompile! Because I added new packages without updating the project.toml, so I had to relearn how to add new dependencies to a package.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"It has been an hour and I still haven't figured out how to automatically get docstrings for functions passed into an index/api page, like they have it over at Molly.jl. Oh well, it is likely far better to get the gh-pages version of the documentation working.","category":"page"},{"location":"devdiary/#2.-3-May-packaging-packages-locally","page":"Developer Diary","title":"2. 3 May - packaging packages locally","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"in order to point a test file to my development package and skipall the githubbing and comppiling, i must","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"pgk() dev ./NaiveDynamics.jl\nusing Revise\nusing NaiveDynamics","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"in that specific order. That way a change can be made in the development-source, and immediately referenced in the test/user file. Thank you very much, Revise.jl/stable. To hell with you, Copilot.","category":"page"},{"location":"devdiary/#Let's-talk-about-DataFrame-ification","page":"Developer Diary","title":"Let's talk about DataFrame-ification","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"In the commits last weekend I was very focused on modifiying this package's structure so that a user, regardless of usecase, could design functions around their data in the ObjectCollection type WITHOUT relying on the order of set items in the type. In the current collect_objects() function, I have this nonsense:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"    simCollection = GenericObjectCollection(\n        fill(step_n, objectcount),\n        fill(\"duck\", objectcount),\n        [1:objectcount;],\n        [SizedVector{3, Float64}(rand(positionRange, 3)) for each in 1:objectcount],\n        [SizedVector{3, Float64}(rand(velocityRange, 3)) for each in 1:objectcount],\n        [SizedVector{3, Float64}(zeros(Float64, 3)) for each in 1:objectcount],\n        )","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"when I would prefer a semantics based method that does not depend on the order of inputs. After a lot of testing I just tossed in a big dataframe and a little dataframe. I ran a 1 step simulation of 100 000 atoms, and execution time took at least 3.7 seconds and processed through a humonculous 2GiB of data. I tweaked it a little, and then it wouldnt run anymore at all for OutOfMemory errors. So it became my new task to performance test again and again on all the different methods and packages I could find for multiplying two arrays by broadcasting. We got to a very good place with generating position vectors:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"position = [MVector{3, Float64}(rand(posRange, 3)) for each in 1:5]","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"and with performing the multiplication, as base.broadcast has no idea how to solve a vector of mutable vectors:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"function posVel_multiply!(position, velocity)\n    for i in eachindex(position)\n        position[i] .*= velocity[i]\n    end\n    return position\nend","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"We had a path to de-dataframe-ification and a massive performance improvement. But we still had not solved the convenience problem, but ya know what? I'm good with inconvenient. I have spent a long time trying to solve a problem that isn't a problem. I can winback my semantics with statements at the beginning of a function, like in simulate where we unwind the datatype hierarchy to pull the position array of arrays out of the \"system\" type. It's a less beautiful solution maybe, but no less effective.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"And how much better is life? Sans parallelism and multithreading–just from algorithmic and datatype-selection improvements– we need to run the 100k simulation out to ~60 steps for it to take as long as the DataFrame's version. And we need to run at least 130 steps to generate as much information as the DataFrame's 1 step. Not that I blame the package's authors, it was a very silly idea to turn a highly versatile data processing tool into the DNA of the organism that forms this Naive package. ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"There are still algorithmic improvements to be made. I wanted to use a vector of mutable vectors, like this:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"using StaticArrays\nusing Distributions\n\nminposition = -5.0\nmaxposition = 5.0\nposRange = Uniform(minposition, maxposition)\nvelRange = Uniform(minposition, maxposition)\nposition = [MVector{3, Float64}(rand(posRange, 3)) for each in 1:5]\nvelocity = [MVector{3, Float64}(rand(velRange, 3)) for each in 1:5]\n\n\nfunction posVel_multiply!(position, velocity)\n    for i in eachindex(position)\n        position[i] .*= velocity[i]\n    end\n    return position\nend\n\nposVel_multiply!(position, velocity)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"but the posVel_multiply! does not work in the simulate!() function, and I have absolutely no clue why. It looks to be an active issue on github, and substituting the mutablevector with a sized vector solves the issue. But at low atoms counts, performance falls back by about 20%, and it balloons as count increases. At 100k atoms, it appears about 10x slower than a mutable vector, at about 3ms for the broadcasted multiplication alone. In context, the sized vector can only multiply the position and velocity vectors in about 50 ms per step, and this is an engine with zero interactions. ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"However the logging of the simulation actually takes longer than everything else under simulate!(), so there are several angles of optimization before we even consider threading or SIMD operations that the compiler doesn't already perform.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"But for now we have an angle of approach a velocity verlet stepper that will help bring the time per step back up to >1 second","category":"page"},{"location":"devdiary/#Towards-a-VerletVelocity-Lennard-Jones-fluid","page":"Developer Diary","title":"Towards a VerletVelocity Lennard-Jones fluid","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"The present implementation of unique_pairlist scales at least with BigO(n^2), drawing out execution time for 1 step at 100k particles to over 20 minutes. So the CellListMap method will be used to calculate neighbors instead until I either learn about how it works or come up with some Naive mapping routine. I wonder if there is some shenanigans to pull around by drawing a weirdly shaped matrix, and in so instantiating it, we will determine all of the unique pairs in the our dataset, then we just have to redraw the matrix into a very long vector. However, maybe the real magic of the CellListMap method is the ability to avoid first defining all unique pairs and then asking which ones are within a given distance. And instead it somehow directly creats a list of unique pairs using the distance as the 'first' metric, rather than the last metric. Whatever it is I do want to continue investigating this and create a real Naive method, just to explore the algorithms and the sense of going from","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"    for i in eachindex(position)\n        for j in eachindex(position) \n            if j > i\n                push!(list, SVector(position[i],position[j]))\n            end\n        end\n    end","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"to something not only more useful, but requiring different coding techniques.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"I haven't an idea how these would even work, so for now let's just make CellListMap operable.So we are not quite making CellListMaps, but neighbor lists instead. Not as fancy but still excellent.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"If the force_currentstep is the sum of each force acting on/within the system, must I necessarily allocate and deallocate an array for each force and then broadcast-add them to force_currentstep, or could I instead perform each force-calculation using force_currentstep as an argument and returning it?  I believe the second method is more memory efficient but less parallelizable, when the first method is parallelizable until my device runs out of memory. Naively, doing work sequentially would look either like a series of equal signs","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"force_currentstep = LennJones_force!(force_currentstep)\nforce_currentstep = coulomb_force!(force_currentstep)\netc","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"or as a nested set of functions","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"force_currentstep = coulomb_force!(LennJones_force!(force_currentstep))","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"For the sake of difference, let's use the nested set one :) . Here's an ambition: a simulation-time optimization-suite that detects pending out of memory error/is system aware and decides if we have to focus on memory management or we can go wild in parallel","category":"page"},{"location":"devdiary/#3.-12-May-curious-learning-moment","page":"Developer Diary","title":"3. 12 May - curious learning moment","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"So today I have overhauled how positions are generated to allow the user to define the size of the box with different sizes in each dimension. This is in preparation for defining a reflective box boundary later on. And we are in a strange situation, when calling the code ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"pairslist = InPlaceNeighborList(x=position, cutoff=0.1, parallel=false)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"in my simulate! function, CellListMap.jl checks the position values' maximum and minimum according to their datatype. This check fails because for whatever reason, the number type in the position vector of vectors is an AbstractFloat, despite verification demonstrating that there are real values here. What is even stranger is that I have asked the datatype of my position numbers immediately after creation, and they are Float64. I even tried changing the definition in the constructor GenericRandomCollector from AbstractFloat's to Float64's. ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Here is the list of things that separate the position vector from it's point of creation to the point of being bassed on to INPL: ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"The vecOfMVecs is created under generate_positions(Collector) and is correctly typed as Float64.\nThe vecOfMVecs is retured from generate_positions(Collector) to the positions spot where simCollection is initialized in collect_objects(Collector) and is incorrectly typed as AbstractFloat. It appears that the initialization of a GenericObjectCollection datatype is corrupting the Float64 to AbstractFloat. This seems as unexpected behavior to me, why would it do this? Redefining the GenericObjectCollection fixes the issue. But why would a concrete type ever be reverted back to an abstract type?","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Because Julia is a bit sneaky with type promotion. I misremembered that Julia never promoted types from concrete to abstract. A way of solving this issue, I have learned, is to introduce parametric typing into my code. And this is very exciting! I didn't quite understand any applications of parametric typing (mostly for lack of effort) and here is one just for me! Parametric typing to prevent promotion, moreover, to perform type inferencing based only on the user input.  ","category":"page"},{"location":"devdiary/#Reworking-broadcasting-and-operators-in-velocity-verlet-method","page":"Developer Diary","title":"Reworking broadcasting and operators in velocity verlet method","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Because we have to work with neighbor listing and mapping to calculate our forces, it's a bit harder to simulate!() by having a nested loop going over every atom. So instead we have to rewrite the calculation of each line somehow. I tried various methods","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Broadcast-broadcast by using a unique syntax","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"⊕(a, b) = a .+ b and then calling .⊕ to reach the data points within our VecOfVecs","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Mapping a broadcasted-operator to our VecOfVecs","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"map!(.*, $a,$b) and map!(./, $a,$b, $a)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Dumloop over each item of the outer-vector, and then broadcast an operation to each item","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"function dumloop_multiply!(d, e)\n    @inbounds for i in eachindex(d)\n        d[i] .*= e[i]\n    end\nend","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"The I tried to make a version with an operator argument, but to no success.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"function dumloop_multiply!(operator d, e)           function dumloop_multiply!(operator d, e)\n    @inbounds for i in eachindex(d)                     @inbounds for i in eachindex(d) \n        d[i] .operator= e[i]                                d[i] = operator(d[i], e[i])\n    end                                                 end\nend                                                  end","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"The goal is to extend the behaviors of arithmetic operators and broadcasting to work directly on Vectors of Vectors. However, maybe I can avoid this nonsense by working on how the force is calculated. And I have done that. ","category":"page"},{"location":"devdiary/#JL-force","page":"Developer Diary","title":"JL force","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"And I quickly ran into a new problem: The neighborlist method in CellListMap.jl returns a vector of tuples (indexA, indexB, distance_as_the_fish_swims), when my algorithms demand vectorized data. I need a neighborlist algorithm to return me a tuple of indexA, indexB, MVector(distanceX, distanceY, distanceZ), distanceLine in order to correctly calculate the component forces and the overall energy of these interactions. Or maybe I can code that myself hahah!","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"This would involve using the CellListMap interface, but I have a streaming method in which each atom is given a block of calculations to run through, so parallelism would primarily come from the top forloop by calculating multiple atoms at once in more or less the same procedure. So I really need to make a naive neighbor list with all of the data I need, or otherwise figure out how to pull that information out of CellListMap, but that place is designed to scare people.","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"A further quandary arises from the highly differing behaviors of neighborlist() and the InPlaceNeighborList(), neighborlist!(), and update!() which is the latter does not return the neighbor list vector of tuples, but a complicated data structure series. It is possible that this series contains my data of xyz distances, but sheesh. It may be happier if I provided box-boundaries, as the compute engine takes a boundary that is either user determined or limited by the values expressable in the data-type of the coordinate (Float64 makes the InPlaceNeighborList object fill up the entire REPL with almost only zeros, we learned from our type promotion earlier). Let's see how slow the sim engine is now, and maybe we might consider making a switch to NearestNeighbors.jl","category":"page"},{"location":"devdiary/#the-simulation-BREAKS","page":"Developer Diary","title":"the simulation BREAKS","text":"","category":"section"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Testing the package as it presently stands, it works fine for 100 atoms, but the upperbound number is falling as I examine it by hitting the mid point between the working number and the failing number. Currently, the simulation crashes out at or below 600 atoms. This is a method error, MethodError: objects of type StaticArraysCore.MVector{3, Float64} are not callable that points to these two lines in Simulator.jl:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"d = position[i] .- position[j]\nforce[i] .+= (24*eps ./ d )((2*σ ./ d).^12 - (σ ./ d).^6)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"WAIT, the fact that some runs show problems and others do not indicate that their atoms are not within the cutoff. It's a gentle bug coming from my work! Very gentle, here's the fixed function:  julia force[i] .+= (24*eps ./ d )((2*σ ./ d).^12 - (σ ./ d).^6)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Onto the next breakage InexactError: trunc(Int64, 3.884345474457886e38). A more severe one, I fear. It points to the neighborlist() function call. We are going to update CellListMap and pray. A new release came about 3 days ago sooo we should be good, right? Oh dear. Going from 1000 to 10 000 particles seems to drastically increase the size of the error here, from about 10^20 to 10^30 through and beyond 10^50. So we have to figure out what value is being created that is so extremely stratospheric, and it is created seemingly each time enough particles are created to exist in less than the cut off. Let's increase cut off and reduce atoms. Now we are getting different errors regardless of using a function or sitting in global scope, outofmemory, invalid array size, invalid array dimensions, and sometimes the truncation error. Each of these errors occur in the neighborlist run. For the truncation error, the problematic calculation is Line 213 of Box.jl. ```_nc = floor.(Int, (xmax .- xmin) / (cutoff / lcell)) ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"NearestNeighbors.jl hass it's own problem that the most recent issue shows a method error that prevents the use of Vector(MVector()) so that may not be a solution.\n\nAh but wait, I did not correctly construct my force updates. Now it is working! I am uncertain how I was obliterating the neighborlist by not calculating forces correctly, but it is a strange world. Now it is not working anymore, after I increased the stepcount. Failing in the neighbor list for multiple different reasons. There are 3 erros, out of memory, invalid arraysize, invalid array dimenions, and they all are genereated in line 482 of CellLists.jl","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia     cl = CellList{N,T}(         nrealparticles=length(x),         numberofcells=prod(box.nc),     )","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"It is almost as though the REPL gets 'gunked' up from multiple rounds of ```simulate!()``` Or that perhaps at times two particles land on top of each other or there is some other issue. The gunking theory fell out because no change resulted in a successful run.\n\nWe have 2 issue classes, truncation from Box.jl 213 and CellLists.jl 482.\n\nWait a minute, perhaps the particles are falling in too close and the forces are spiraling out of control. Changing epsilon by 1000x either way seemed to have little effect. While reducing sigma by 1000x seemed to improve success and increasing seemed to mkae failure fairly common. However, success is not guaranteed within 100 or 1000 runs. Hopefully with a pruning routine, things will turn out just fine. An additional helper is increasing the cutoff. Perhaps a class of errors, or maybe jsut a specifc error or a few can be eliminated with a high enough cut-off or dense enough conditions to guarantee that the neighbor list is not empty.\n\n19 May\nEven with the changes, the naive pruning and the like, we are still getting NotANumber answers, which may indicated an enduring problem with parameterization in the neighbor cutoff and in the time width and in the particle density and etc. But at least the simualtion runs without dying now, if it runs inconsistently due to the use of in-Verlet try catch blocking. \n\nA fairly curious discussion comes around strategies for conserving energy. At present, our work is purely additive. Seemingly after the first step, all particles will be slammed into the walls of the simulation box.\n\n\n## 4. 24 May - Death to allocations\n\nSo my issue with CellListMap is a limitation of the method as a whole, whose memory scales with the volume of space being considered, or something like that, and my highly disperse simulations seem to force the algorithm to consider the whole numeric width of Float64 for calculating the neighbor list. Thanks to the university of michigan for their informative article.\n\n\nBefore I worry about pulling in NearestNeighbors.jl or seeing how long it would take to make a naive BVH neighbor finder, I am allocation hunting in my simulation to increase speed. I was primarily worried that ```force_currentstep = force_nextstep``` would de/allocate, as I often run into the problem that ```a = 5, b = a, b += 1, but a !== 6```, but the compiler knows what it's doing. We instead run into a much more interesting problem:\n\nTo perform Velocity-Verlet integration, we use broadcasting to calculate the xyz-components of position for each particle:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia position[i] = position[i] .+ (velocity[i] .* stepwidth) .+ (force_currentstep[i] ./ mass[i] .* stepwidth^2/2)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Benchmarking showed an allocation was made, so I set to improve it:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia positionJ[i] .+= ((velocity[i] .* stepwidth) .+ (force_currentstep[i] ./ mass[i] .* stepwidth^2/2))","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"\nThe two methods should obviously (to me) produce the same output, and are seemingly just format differences. However when calculating positionJ, we increase speed, 16 -> 10 ns, and eliminate allocation, 32 bytes -> 0. That alone, positionJ seems to be the idea choice. But why the difference?\n\nMore importantly, what about correctness? positionJ and position produce different results about 5% of the time. It turns out positionJ's method is internally consistent, while position's is not internally consistent. And that is wild.\n\nWe find internal consistency by either removing the velocity-stepwidth term, or by using positionJ's method. Removing the addition of ```(force_currentstep[i] ./ mass[i] .* stepwidth^2/2)``` to position does not affect internal consistency. Furthermore, switching the order of operations","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia position[i] = position[i]  .+ (forcecurrentstep[i] ./ mass[i] .* stepwidth^2/2) .+ (velocity[i] .* stepwidth) positionK[i] = positionK[i] .+ (velocity[i] .* stepwidth) .+ (forcecurrentstep[i] ./ mass[i] .* stepwidth^2/2)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"also has no affect, position and positionK's methods are still inconsistent with each other.\n\nSo, I just made my code faster* and more precise by changing how it was spelled. What a weird world. *A savings of 6 ns per calculation doesn't register at the ms level in my short-small test, but memory usage and allocations are reduced by 6.7 and 7.7 percent, respectively. \n\nThe next line of question, why is simulate!() (with neighborlisting and force-calculating deactivated) so slow and allocating so often? Internally, the function should allocate only a few times, with each action taking fewer than 50 ns, and most actions taking fewer than 20 ns. Changing the index scheme from ```for step_n in 1:steps``` to ```for step_n in eachindex(step_array) where step_array = [1:steps;]``` reduced allocations by 1. Further changing this scheme to a zeros-array that is steps long reduced allocations by 51. Testing shows that allocations scale linearly with the number of steps, which is incorrect.\n\nSo my old method will allocate several intermediate array slices on the heap. If I run away from the inner for loop for each particle, I drop allocations by half with no further optimization. Each operation allocates a new intermediate array. So we have to use the staticarray to get over this problem\n","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"28.200 μs (3057 allocations: 122.11 KiB) with mutable Vector  13.600 μs (57 allocations: 78.73 KiB) static vector","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"finally. Well not yet, because we still have allocation scaling with step length, so changing datatypes is no sure-fire solution.\n\nAfter testing, a problem is shown with how Julia processes complex expressions, such as the position-update:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia position[i] += velocity[i] * stepwidth .+ force_currentstep[i] ./ mass[i] .* stepwidth^2/2","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Several arrays are here allocated and deallocated within the string, and when we have for-each-step and for-each-particle, we end up with absurd allocation figures and runtimes. When we decompose this expression and we allow the compiler to run  on the entire block of particles positions, we obtain extreme speed and constant allocation for simulation size. The only problem is *readability*. The position calculation becomes:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia positionIntermediate1 = velocity dumloopmultiply!(positionIntermediate1, stepwidth) positionIntermediate2 = forcecurrentstep  dumloopdivide!(positionIntermediate2, mass)  dumloopmultiply!(positionIntermediate1, stepwidthSqrdHalf) dumloopadd!(position, positionIntermediate1)   dumloopadd!(position, positionIntermediate2)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"where","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"function dumloop_multiply(vec::vectorOfVectors, vec2::vectorOfVectors)     for i in eachindex(vec)         vec[i] .*= vec2     end end","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"We avoid any allocations within for-each-step by writing over intermediate values  at each step. These are generated ahead of the simulation loop. I've made multiple attempts with nested broadcasting or broadcasted mapping, and these methods result in allocations for each particle, but reducing each value transformation to either a direct substitution or a loop'ed broadcast worked best. Here is where things get really confusing. As part of updating position and velocity due to only the velocity and apparent forces, we have to evaulate 9 for-each-particle loops at every simulation step. So what if we reduced the loops into a single loop which defines a block of numbers to crunch for every particle. That was my original idea in this simulation. Julia hates this idea:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia for stepn in eachindex(stepsarray)","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"    for i in eachindex(objectindex)\n\n        positionIntermediate1[i] = velocity[i] \n        positionIntermediate1[i] .*= stepwidth\n        positionIntermediate2[i] = force_currentstep[i] \n        positionIntermediate2[i] ./= mass[i] \n        positionIntermediate2[i] .*= stepwidthSqrdHalf\n        position[i] .+= positionIntermediate1[i] \n        position[i] .+= positionIntermediate2[i]\n\n        velocityIntermediate1[i] .= force_currentstep[i] .* force_nextstep[i]\n        velocityIntermediate1[i] ./= mass[i]\n        velocityIntermediate1[i] .*= stepwidthHalf\n        velocity[i] .+= velocityIntermediate1[i]\n\n    end","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"end","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"Where numbers are crunched, zero allocations occur. But through the nested looping, an obscene number of allocations are made. ","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia #TODO make this into a table please thanks #1. which package? I know in my hunting there is a package big on the tables. Might jsut be Documenter.jl or an extension","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"5 steps, 100 particles\n9 loops: 24.600 μs (415 allocations: 16.70 KiB)\n1 loop: (9915 allocations: 313.50 KiB)\n\n5 steps, 100 particles\n9 loops: 111.600 μs (415 allocations: 16.75 KiB)\n1 loop: 29.068 ms (95415 allocations: 2.91 MiB)\nFor reference, the naive position expression is at least 3x slower the 9-loop on run time, but about half the allocations as the 1-loop.\n\nI am rather confused about how Julia optimizes these 2 methods. I prefer the second method because I can parallelize it infinitely with a macro tacked in front of the for-each-particle loop, but as it is presently written, Julia cannnot handle it well. And I am certain there exists a simple routine to parallelize the 9-loop method.\n\n\nAnother point of consideration is using StaticVectors over MutableVectors to contain dimensional data. We can just avoid loop hell, keep the syntax clean-ish, and improve performance and allocations. But static vectors aren't as workable. You cannot iterate, broadcast, map over them, so then I have no idea how to institute boundary conditions if I cannot analyze or affect any particular value. However, I could instead use StaticArrays methods to affect test mutable-vectors, and depending on the values within these test vectors, I can apply action vectors over the elements of our static vectors. This could make for a beautiful evaluation, and allow me to get rid of the naive boundary function:","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"julia function boundaryreflect!(ithCoord, ithVelo, collector::Collector)     # can this be evaluated more efficiently?     #restructureing would allow a simple forloop     if collector.minxDim > ithCoord[1]          ithVelo[1] = -ithVelo[1]          ithCoord[1] = collector.minxDim     end     if collector.maxxDim < ithCoord[1]          ithVelo[1] = -ithVelo[1]          ithCoord[1] = collector.max_xDim     end","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"if collector.min_yDim > ithCoord[2] \n    ithVelo[2] = -ithVelo[2] \n    ithCoord[2] = collector.min_yDim\nend\nif collector.max_yDim < ithCoord[2] \n    ithVelo[2] = -ithVelo[2] \n    ithCoord[2] = collector.max_yDim\nend\n\nif collector.min_zDim > ithCoord[3] \n    ithVelo[3] = -ithVelo[3] \n    ithCoord[3] = collector.min_zDim\nend\nif collector.max_zDim < ithCoord[3] \n    ithVelo[3] = -ithVelo[3] \n    ithCoord[3] = collector.max_zDim\nend","category":"page"},{"location":"devdiary/","page":"Developer Diary","title":"Developer Diary","text":"end At the moment, my attempt to make asimulate_unified!()``` for the SVector hasn't worked, it allocates scaling with sim duration and becomes increasingly slow with duration. Some more time spent looking at the work may help, such as trying to restream the functions into a single task, rather than the current split method we are rocking with.","category":"page"},{"location":"","page":"Index","title":"Index","text":"../../README.md","category":"page"}]
}
